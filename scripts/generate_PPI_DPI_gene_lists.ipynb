{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "949e6b4d",
   "metadata": {},
   "source": [
    "# Generate PPI, DPI, and gene lists\n",
    "\n",
    "This generates the three inputs for network analysis: a protein-protein interaction (PPI) list, a drug-protein interaction (DPI) list, and a gene list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bdcd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae118a4",
   "metadata": {},
   "source": [
    "## Create the combined PPI list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d805379b",
   "metadata": {},
   "source": [
    "Load and reformat the downloaded interactomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6c25670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/_lmfmp3j465cx8tv39t1vmnh0000gn/T/ipykernel_1916/1759536536.py:8: DtypeWarning: Columns (1,2,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  biogrid_PPI = pd.read_csv(\"../data/networks/BIOGRID-MV-Physical-4.4.245.tab3.txt\", sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "# ====== 1. STRING ======\n",
    "# Load reformatted STRING data (reformatting done in R using biomaRt)\n",
    "string_PPI = pd.read_csv(\"../data/networks/string_PPI.csv\", sep=\",\")\n",
    "\n",
    "\n",
    "# ====== 2. BioGRID ======\n",
    "# Load BioGRID data\n",
    "biogrid_PPI = pd.read_csv(\"../data/networks/BIOGRID-MV-Physical-4.4.245.tab3.txt\", sep=\"\\t\")\n",
    "\n",
    "# Filter to keep only human interactions\n",
    "biogrid_PPI = biogrid_PPI[\n",
    "    (biogrid_PPI[\"Organism ID Interactor A\"] == 9606) &\n",
    "    (biogrid_PPI[\"Organism ID Interactor B\"] == 9606)\n",
    "]\n",
    "\n",
    "# Filter and reformat\n",
    "biogrid_PPI = biogrid_PPI[[\"Official Symbol Interactor A\", \"Official Symbol Interactor B\"]]\n",
    "biogrid_PPI.columns = [\"GeneA\", \"GeneB\"]\n",
    "biogrid_PPI.to_csv(\"../data/networks/biogrid_PPI.csv\", index=False)\n",
    "\n",
    "\n",
    "# ====== 3. HINT ======\n",
    "# Load HINT data\n",
    "hint_PPI = pd.read_csv(\"../data/networks/HINT_HomoSapiens_binary_hq.txt\", sep=\"\\t\")\n",
    "\n",
    "# Filter and reformat\n",
    "hint_PPI = hint_PPI[[\"Gene_A\", \"Gene_B\"]]\n",
    "hint_PPI.columns = [\"GeneA\", \"GeneB\"]\n",
    "hint_PPI.to_csv(\"../data/networks/hint_PPI.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0b7e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dataset  Num_Interactions\n",
      "0  BIOGRID            318015\n",
      "1   STRING            207024\n",
      "2     HINT            163435\n"
     ]
    }
   ],
   "source": [
    "# Create summary table\n",
    "ppi_counts = pd.DataFrame({\n",
    "    \"Dataset\": [\"BIOGRID\", \"STRING\", \"HINT\"],\n",
    "    \"Num_Interactions\": [\n",
    "        len(biogrid_PPI),\n",
    "        len(string_PPI),\n",
    "        len(hint_PPI)\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Print the table\n",
    "print(ppi_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5986c8",
   "metadata": {},
   "source": [
    "Combine all PPI networks into one list without duplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4789859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined PPI, length: 688474\n",
      "After removing rows with empty entry, length: 678651\n",
      "After removing self-loops, length: 666715\n",
      "After removing duplicates, length: 666715\n",
      "After removing bidirectional duplicates, length: 345547\n",
      "Combined PPI network saved as 'combined_PPI.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine all PPI networks\n",
    "combined_ppi = pd.concat([biogrid_PPI, string_PPI, hint_PPI], ignore_index=True)\n",
    "print(\"Combined PPI, length:\", len(combined_ppi))\n",
    "\n",
    "# Remove empty rows\n",
    "combined_ppi = combined_ppi.dropna()\n",
    "print(\"After removing rows with empty entry, length:\", len(combined_ppi))\n",
    "\n",
    "# Remove self-loops\n",
    "combined_ppi = combined_ppi[combined_ppi[\"GeneA\"] != combined_ppi[\"GeneB\"]]\n",
    "print(\"After removing self-loops, length:\", len(combined_ppi))\n",
    "\n",
    "# Remove duplicates in both directions\n",
    "combined_ppi.drop_duplicates()\n",
    "print(\"After removing duplicates, length:\", len(combined_ppi))\n",
    "combined_ppi[\"sorted_pair\"] = combined_ppi.apply(lambda row: tuple(sorted([row[\"GeneA\"], row[\"GeneB\"]])), axis=1)\n",
    "combined_ppi = combined_ppi.drop_duplicates(subset=\"sorted_pair\")\n",
    "combined_ppi = combined_ppi.drop(columns=\"sorted_pair\")\n",
    "print(\"After removing bidirectional duplicates, length:\", len(combined_ppi))\n",
    "\n",
    "# Save combined PPI\n",
    "combined_ppi.to_csv(\"../data/networks/combined_PPI.csv\", index=False)\n",
    "print(\"Combined PPI network saved as 'combined_PPI.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc060cd",
   "metadata": {},
   "source": [
    "## Create the drug-gene interaction list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b072e92",
   "metadata": {},
   "source": [
    "### DrugBank\n",
    "From DrugBank, I take the files bonds.csv, polypeptides.csv, and bio_entities.csv and combine them to generate a drug-gene interaction list containing the drug bank ID and then the gene name of the protein it interacts with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cb676d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading dataframes...\n",
      "\n",
      "\n",
      "Filtering dataframes...\n",
      "\n",
      "\n",
      "Merging dataframes...\n",
      "\n",
      "Number of unique approved DrugBank drugs: 1863\n",
      "Total DPI rows for approved drugs: 3698\n",
      "\n",
      "Total drug–gene pairs: 2879\n",
      "With drug names: 2879\n",
      "\n",
      "Final DrugBank DPI head:\n",
      "              Drug_Name Drug_Target\n",
      "0            Cetuximab        EGFR\n",
      "1         Dornase alfa      DNASE1\n",
      "2  Denileukin diftitox       IL2RA\n",
      "3  Denileukin diftitox       IL2RB\n",
      "4           Etanercept         TNF\n",
      "\n",
      "Number of unique drugs: 1438\n",
      "Number of unique target genes: 790\n",
      "\n",
      "Final DrugBank DPI dimensions: (2873, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============== Load data ==============\n",
    "\n",
    "print(\"\\nLoading dataframes...\\n\")\n",
    "\n",
    "bonds = pd.read_csv(\"../data/networks/milner_drugbank_postgresql/bonds.csv\", sep=\",\", header=None)\n",
    "bonds.columns = [\n",
    "    \"id\", \"type\", \"drug_id\", \"biodb_id\", \"pdb_id\", \"position\",\n",
    "    \"pharmacological_action\", \"antagonist\", \"agonist\", \"substrate\",\n",
    "    \"inhibitor\", \"inducer\", \"other_action\", \"inducer_strength\",\n",
    "    \"inhibitor_strength\", \"induction_clinically_sig\", \"inhibition_clinically_sig\"\n",
    "]\n",
    "\n",
    "polypeptides = pd.read_csv(\"../data/networks/milner_drugbank_postgresql/polypeptides.csv\", sep=\",\", header=None)\n",
    "polypeptides.columns = [\n",
    "    \"uniprot_id\", \"name\", \"uniprot_name\", \"gene_name\", \"organism_id\",\n",
    "    \"molecular_weight\", \"theoretical_pi\", \"general_function\", \"specific_function\",\n",
    "    \"signal_regions\", \"transmembrane_regions\", \"pdb_ids\", \"genbank_gene_id\",\n",
    "    \"genbank_protein_id\", \"genecard_id\", \"locus\", \"genatlas_id\", \"hgnc_id\",\n",
    "    \"meta_cyc_id\", \"ncbi_sequence_ids\", \"tissue_specificity\", \"cofactor\",\n",
    "    \"subunit\", \"cellular_location\", \"amino_acid_sequence\", \"gene_sequence\"\n",
    "]\n",
    "\n",
    "bio_entities = pd.read_csv(\"../data/networks/milner_drugbank_postgresql/bio_entities.csv\", sep=\",\", header=None)\n",
    "bio_entities.columns = [\n",
    "    \"biodb_id\", \"name\", \"kind\", \"organism\"\n",
    "]\n",
    "\n",
    "drugs = pd.read_csv(\"../data/networks/milner_drugbank_postgresql/drugs.csv\", sep=\",\", header=None)\n",
    "drugs.columns = [\n",
    "    \"id\", \"type\", \"drugbank_id\", \"name\", \"state\", \"description\",\n",
    "    \"simple_description\", \"clinical_description\", \"cas_number\",\n",
    "    \"protein_formula\", \"protein_weight\", \"investigational\", \"approved\",\n",
    "    \"vet_approved\", \"experimental\", \"nutraceutical\", \"illicit\", \"withdrawn\",\n",
    "    \"moldb_mono_mass\", \"moldb_inchi\", \"moldb_inchikey\", \"moldb_smiles\",\n",
    "    \"moldb_average_mass\", \"moldb_formula\", \"synthesis_patent_id\",\n",
    "    \"protein_weight_details\", \"biotech_kind\"\n",
    "]\n",
    "\n",
    "# Rename column for clarity\n",
    "drugs.rename(columns={\"id\": \"drug_id\", \"name\": \"drug_name\"}, inplace=True)\n",
    "\n",
    "# Print head of each DataFrame\n",
    "# print(\"Bonds DataFrame head:\")\n",
    "# print(bonds.head())\n",
    "# print(\"\\nPolypeptides DataFrame head:\")\n",
    "# print(polypeptides.head())\n",
    "# print(\"\\nBio Entities DataFrame head:\")\n",
    "# print(bio_entities.head())\n",
    "# print(\"\\nDrugs DataFrame head:\")\n",
    "# print(drugs.head())\n",
    "\n",
    "\n",
    "# ============== Filter dataframes ==============\n",
    "\n",
    "print(\"\\nFiltering dataframes...\\n\")\n",
    "\n",
    "# Filter for target bonds with pharmacological action\n",
    "target_bonds = bonds[\n",
    "    (bonds[\"type\"] == \"TargetBond\") &\n",
    "    (bonds[\"pharmacological_action\"] == \"yes\")\n",
    "].copy()\n",
    "target_bonds = target_bonds[[\"drug_id\", \"biodb_id\"]]\n",
    "\n",
    "# Filter for human proteins\n",
    "polypeptides = polypeptides[polypeptides[\"organism_id\"] == 154].copy()\n",
    "polypeptides = polypeptides[[\"name\", \"gene_name\"]]\n",
    "\n",
    "# Filter for human proteins\n",
    "bio_entities = bio_entities[\n",
    "    (bio_entities[\"kind\"] == \"protein\") &\n",
    "    (bio_entities[\"organism\"] == \"Humans\")\n",
    "].copy()\n",
    "bio_entities = bio_entities[[\"biodb_id\", \"name\"]]\n",
    "\n",
    "# Filter for drugs approved or in clinical trials, exclude non-human, illicit, nutraceutical, or withdrawn\n",
    "drugs = drugs[\n",
    "    (drugs[\"approved\"] == 1) &\n",
    "    (drugs[\"withdrawn\"] == 0) &\n",
    "    (drugs[\"illicit\"] == 0) &\n",
    "    (drugs[\"nutraceutical\"] == 0)\n",
    "].copy()\n",
    "\n",
    "# Filter for id, drug bank id, and name\n",
    "drugs = drugs[[\"drug_id\", \"drugbank_id\", \"drug_name\"]]\n",
    "\n",
    "# ============== Merge dataframes ==============\n",
    "\n",
    "print(\"\\nMerging dataframes...\\n\")\n",
    "\n",
    "# Merge drug ID's with protein names\n",
    "drug_protein = target_bonds.merge(bio_entities, on=\"biodb_id\", how=\"left\")\n",
    "\n",
    "# Merge with gene names\n",
    "drug_gene = drug_protein.merge(polypeptides, on=\"name\", how=\"left\")\n",
    "\n",
    "# Merge with drug bank IDs and drug names\n",
    "drug_gene = drug_gene.merge(drugs, on=\"drug_id\", how=\"inner\") # Keep only rows where drug_id exists in both dfs\n",
    "\n",
    "# Check number of unique approved drugs before final formatting\n",
    "approved_only = drug_gene[drug_gene[\"drugbank_id\"].notna()]\n",
    "print(f\"Number of unique approved DrugBank drugs: {approved_only['drug_name'].nunique()}\")\n",
    "print(f\"Total DPI rows for approved drugs: {len(approved_only)}\")\n",
    "\n",
    "# Drop missing target gene names\n",
    "drug_gene = drug_gene.dropna(subset=[\"gene_name\"])\n",
    "\n",
    "# ========= Save one DataFrame with DrugBank IDs for future reference\n",
    "drug_gene_final_with_id = drug_gene[[\"drug_id\", \"drug_name\", \"gene_name\"]]\n",
    "drug_gene_final_with_id.columns = [\"Drug_ID\", \"Drug_Name\", \"Drug_Target\"]\n",
    "drug_gene_final_with_id = drug_gene_final_with_id.dropna()\n",
    "drug_gene_final_with_id = drug_gene_final_with_id.drop_duplicates()\n",
    "drug_gene_final_with_id.to_csv(\"../data/networks/drugbank_DPI_with_ID.csv\", index=False)\n",
    "# ===================================================================\n",
    "\n",
    "# Extract and clean final DataFrame\n",
    "drug_gene_final = drug_gene[[\"drug_name\", \"gene_name\"]]\n",
    "drug_gene_final.columns = [\"Drug_Name\", \"Drug_Target\"]\n",
    "\n",
    "# Verify number of rows with named drugs\n",
    "total_rows = len(drug_gene_final)\n",
    "missing_names = drug_gene_final[\"Drug_Name\"].isna().sum()\n",
    "named_rows = total_rows - missing_names\n",
    "print(\"\\nTotal drug–gene pairs:\", total_rows)\n",
    "print(\"With drug names:\", named_rows)\n",
    "\n",
    "# Remove rows with NaN and duplicates\n",
    "drug_gene_final = drug_gene_final.dropna()\n",
    "drug_gene_final = drug_gene_final.drop_duplicates()\n",
    "\n",
    "# Print key info\n",
    "print(\"\\nFinal DrugBank DPI head:\\n\", drug_gene_final.head())\n",
    "print(\"\\nNumber of unique drugs:\", drug_gene_final[\"Drug_Name\"].nunique())\n",
    "print(\"Number of unique target genes:\", drug_gene_final[\"Drug_Target\"].nunique())\n",
    "print(\"\\nFinal DrugBank DPI dimensions:\", drug_gene_final.shape)\n",
    "\n",
    "# Save final DPI list\n",
    "drug_gene_final.to_csv(\"../data/networks/drugbank_DPI.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b23dd5",
   "metadata": {},
   "source": [
    "### ChEMBL\n",
    "From CheMBL, I downloaded the chembl_35_sqlite.tar.gz file from version 35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3ffc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying ChEMBL DPI...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fc788883640>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hannahbazin/Desktop/Cambridge/Academics/Han_Lab/MPhil/mphil-project/bat_proximity_analysis/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DPI head before target mapping:\n",
      "    molregno target_chembl_id\n",
      "0    179188        CHEMBL235\n",
      "1     33632        CHEMBL259\n",
      "2     33415        CHEMBL259\n",
      "3     33415       CHEMBL3795\n",
      "4    219299       CHEMBL3974\n",
      "\n",
      "Number of unique drugs: 673271\n",
      "Number of unique targets: 3768\n",
      "\n",
      "DPI shape before target mapping: (1088205, 2)\n",
      "\n",
      "Mapping ChEMBL target IDs to UniProt...\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/networks/chembl_35/chembl_35_sqlite/chembl_uniprot_mapping.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# ============== Map target ChEMBL IDs to UniProt IDs ==============\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMapping ChEMBL target IDs to UniProt...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m uniprot_map \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/networks/chembl_35/chembl_35_sqlite/chembl_uniprot_mapping.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m uniprot_map\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_uniprot_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_chembl_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     49\u001b[0m uniprot_map \u001b[38;5;241m=\u001b[39m uniprot_map[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_chembl_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_uniprot_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m~/Desktop/Cambridge/Academics/Han_Lab/MPhil/mphil-project/bat_proximity_analysis/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Cambridge/Academics/Han_Lab/MPhil/mphil-project/bat_proximity_analysis/lib/python3.9/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/Cambridge/Academics/Han_Lab/MPhil/mphil-project/bat_proximity_analysis/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Cambridge/Academics/Han_Lab/MPhil/mphil-project/bat_proximity_analysis/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/Cambridge/Academics/Han_Lab/MPhil/mphil-project/bat_proximity_analysis/lib/python3.9/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/networks/chembl_35/chembl_35_sqlite/chembl_uniprot_mapping.txt'"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# ============== Connect to ChEMBL database ==============\n",
    "\n",
    "conn = sqlite3.connect(\"../data/networks/chembl_35/chembl_35_sqlite/chembl_35.db\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# ============== Query high-confidence durg-protein interactions ==============\n",
    "\n",
    "print(\"\\nQuerying ChEMBL DPI...\\n\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    activities.molregno,\n",
    "    target_dictionary.chembl_id AS target_chembl_id\n",
    "FROM\n",
    "    activities\n",
    "JOIN\n",
    "    assays ON activities.assay_id = assays.assay_id\n",
    "JOIN\n",
    "    target_dictionary ON assays.tid = target_dictionary.tid\n",
    "JOIN\n",
    "    target_components ON target_dictionary.tid = target_components.tid\n",
    "JOIN\n",
    "    component_sequences ON target_components.component_id = component_sequences.component_id\n",
    "WHERE\n",
    "    activities.standard_relation = '='\n",
    "    AND activities.standard_type IN ('IC50', 'Ki', 'Kd', 'EC50')\n",
    "    AND activities.standard_value IS NOT NULL\n",
    "    AND component_sequences.organism = 'Homo sapiens'\n",
    "\"\"\"\n",
    "\n",
    "chembl_dpi = pd.read_sql(query, conn)\n",
    "print(\"DPI head before target mapping:\\n\", chembl_dpi.head())\n",
    "print(\"\\nNumber of unique drugs:\", chembl_dpi[\"molregno\"].nunique())\n",
    "print(\"Number of unique targets:\", chembl_dpi[\"target_chembl_id\"].nunique())\n",
    "print(\"\\nDPI shape before target mapping:\", chembl_dpi.shape)\n",
    "\n",
    "# ============== Map target ChEMBL IDs to UniProt IDs ==============\n",
    "\n",
    "print(\"\\nMapping ChEMBL target IDs to UniProt...\\n\")\n",
    "\n",
    "uniprot_map = pd.read_csv(\"../data/networks/chembl_35/chembl_35_sqlite/chembl_uniprot_mapping.txt\", sep=\"\\t\", header=None, skiprows=1)\n",
    "uniprot_map.columns = [\"target_uniprot_id\", \"target_chembl_id\", \"target_name\", \"target_type\"]\n",
    "uniprot_map = uniprot_map[[\"target_chembl_id\", \"target_uniprot_id\"]]\n",
    "\n",
    "chembl_dpi_final = chembl_dpi.merge(uniprot_map, on=\"target_chembl_id\", how=\"left\")\n",
    "chembl_dpi_final = chembl_dpi_final.dropna()\n",
    "print(\"DPI head after target mapping:\\n\", chembl_dpi_final.head())\n",
    "print(\"\\nDPI shape after target mapping:\", chembl_dpi.shape)\n",
    "\n",
    "# Save intermediate DPI\n",
    "chembl_dpi_final.to_csv(\"../data/networks/inter_chembl_DPI.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3015aa",
   "metadata": {},
   "source": [
    "The mapping of target UniProt IDs to target gene names was done in R. The next step is to convert the drug molregno IDs to actual ChEMBL IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47968445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading compound info and filtering...\n",
      "\n",
      "Summary of therapeutic stats after filtering:\n",
      "\n",
      "=== max_phase ===\n",
      "max_phase\n",
      "4.0    15357\n",
      "3.0      105\n",
      "2.0        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== therapeutic_flag ===\n",
      "therapeutic_flag\n",
      "1    15464\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== molecule_type ===\n",
      "molecule_type\n",
      "Small molecule     15188\n",
      "Protein              234\n",
      "Unknown               39\n",
      "Oligosaccharide        2\n",
      "None                   1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final formatting and export...\n",
      "\n",
      "Before removing duplicates: 15464\n",
      "After removing duplicates: 14253\n",
      "Final ChEMBL DPI head:\n",
      "    Drug_Name Drug_Target\n",
      "0  CLONIDINE      ADRA1A\n",
      "1  CLONIDINE      ADRA1D\n",
      "2  CLONIDINE      ADRA1B\n",
      "3  CLONIDINE      ADRA2A\n",
      "4  CLONIDINE      ADRA2C\n",
      "\n",
      "Number of unique drugs: 1594\n",
      "Number of unique target genes: 1649\n",
      "\n",
      "Final ChEMBL DPI dimensions: (14253, 2)\n",
      "Number of unique drug–gene interaction pairs: 14253\n"
     ]
    }
   ],
   "source": [
    "# ============== Map target UniProt IDs to gene names in R ==============\n",
    "#\n",
    "# See network_reformatting_DPI.Rmd\n",
    "#\n",
    "# ============== Annotate with compound names and filter for therapeutic use ==============\n",
    "\n",
    "print(\"\\nLoading compound info and filtering...\\n\")\n",
    "\n",
    "# Load annotated DPI\n",
    "chembl_dpi = pd.read_csv(\"../data/networks/annotated_chembl_dpi.csv\", sep=\",\")\n",
    "\n",
    "# Query to get compound names\n",
    "compound_info_query = \"\"\"\n",
    "SELECT\n",
    "    molregno,\n",
    "    chembl_id AS compound_chembl_id,\n",
    "    pref_name AS compound_name\n",
    "FROM\n",
    "    molecule_dictionary\n",
    "\"\"\"\n",
    "compound_info = pd.read_sql(compound_info_query, conn)\n",
    "\n",
    "# Merge to get compound name\n",
    "chembl_dpi = chembl_dpi.merge(compound_info, on=\"molregno\", how=\"left\")\n",
    "\n",
    "# Query to get clinical phase and therapeutic use info\n",
    "compound_meta_query = \"\"\"\n",
    "SELECT chembl_id, max_phase, therapeutic_flag, molecule_type\n",
    "FROM molecule_dictionary\n",
    "\"\"\"\n",
    "compound_meta = pd.read_sql(compound_meta_query, conn)\n",
    "\n",
    "compound_meta = compound_meta[\n",
    "    (compound_meta[\"max_phase\"] >= 1) &        # Keep phase I or higher (approved or in clinical trials)\n",
    "    (compound_meta[\"therapeutic_flag\"] == 1)   # Keep compounds intended for therapeutic use\n",
    "]\n",
    "compound_meta = compound_meta.dropna(subset=[\"max_phase\"])\n",
    "compound_meta = compound_meta.dropna(subset=[\"therapeutic_flag\"])\n",
    "\n",
    "# Merge to retain only clinically relevant compounds\n",
    "chembl_dpi = chembl_dpi.merge(compound_meta, left_on=\"compound_chembl_id\", right_on=\"chembl_id\", how=\"inner\")\n",
    "chembl_dpi = chembl_dpi.drop(columns=[\"chembl_id\"])\n",
    "\n",
    "# Save intermediate DPI with compound names and meta info\n",
    "chembl_dpi_with_meta = chembl_dpi.copy()\n",
    "chembl_dpi_with_meta = chembl_dpi_with_meta.drop_duplicates(subset=[\"compound_name\", \"gene_name\"])\n",
    "chembl_dpi_with_meta.to_csv(\"../data/networks/chembl_DPI_with_meta.csv\", index=False)\n",
    "\n",
    "# Verify filtering\n",
    "print(\"Summary of therapeutic stats after filtering:\")\n",
    "print(\"\\n=== max_phase ===\")\n",
    "print(chembl_dpi[\"max_phase\"].value_counts(dropna=False))\n",
    "print(\"\\n=== therapeutic_flag ===\")\n",
    "print(chembl_dpi[\"therapeutic_flag\"].value_counts(dropna=False))\n",
    "print(\"\\n=== molecule_type ===\")\n",
    "print(chembl_dpi[\"molecule_type\"].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "# ============== Final processing and export ==============\n",
    "\n",
    "print(\"\\nFinal formatting and export...\\n\")\n",
    "\n",
    "# Rename columns and remove unnamed drugs\n",
    "chembl_dpi_final = chembl_dpi[[\"compound_name\", \"gene_name\"]].copy()\n",
    "chembl_dpi_final.columns = [\"Drug_Name\", \"Drug_Target\"]\n",
    "chembl_dpi_final = chembl_dpi_final.dropna(subset=[\"Drug_Name\"])\n",
    "\n",
    "# Drop duplicates\n",
    "print(\"Before removing duplicates:\", len(chembl_dpi_final))\n",
    "chembl_dpi_final = chembl_dpi_final.drop_duplicates()\n",
    "print(\"After removing duplicates:\", len(chembl_dpi_final))\n",
    "\n",
    "# Print key info\n",
    "print(\"Final ChEMBL DPI head:\\n\", chembl_dpi_final.head())\n",
    "print(\"\\nNumber of unique drugs:\", chembl_dpi_final[\"Drug_Name\"].nunique())\n",
    "print(\"Number of unique target genes:\", chembl_dpi_final[\"Drug_Target\"].nunique())\n",
    "print(\"\\nFinal ChEMBL DPI dimensions:\", chembl_dpi_final.shape)\n",
    "num_unique_interactions = chembl_dpi_final.drop_duplicates(subset=[\"Drug_Name\", \"Drug_Target\"]).shape[0]\n",
    "print(f\"Number of unique drug–gene interaction pairs: {num_unique_interactions}\")\n",
    "\n",
    "# Save final ChEMBL DPI DataFrame\n",
    "chembl_dpi_final.to_csv(\"../data/networks/chembl_DPI.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2bcf306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique approved drugs in ChEMBL DPI: 1588\n",
      "Total DPI rows for approved drugs: 14146\n"
     ]
    }
   ],
   "source": [
    "# Check how many unique approved drugs are in ChEMBL DPI\n",
    "approved_only = chembl_dpi_with_meta[chembl_dpi_with_meta[\"max_phase\"] == 4]\n",
    "print(f\"Number of unique approved drugs in ChEMBL DPI: {approved_only['compound_name'].nunique()}\")\n",
    "print(f\"Total DPI rows for approved drugs: {len(approved_only)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e57808",
   "metadata": {},
   "source": [
    "## Merge DrugBank and ChEMBL DPI lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f23002b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique drug names in ChEMBL: 1594\n",
      "Number of unique drug names in DrugBank: 1438\n",
      "Number of shared drug names: 783\n",
      "Total drug-target interactions before removing duplicates: 17126\n",
      "Total drug-target interactions after removing duplicates: 15951\n",
      "Total unique drug-target interactions: 15951\n",
      "Number of unique drugs: 2249\n",
      "Number of unique targets: 1933\n"
     ]
    }
   ],
   "source": [
    "# Load lists of drug–gene pairs from DrugBank and ChEMBL\n",
    "drugbank_dpi = pd.read_csv(\"../data/networks/drugbank_DPI.csv\", sep=\",\")\n",
    "chembl_dpi = pd.read_csv(\"../data/networks/chembl_DPI.csv\", sep=\",\")\n",
    "\n",
    "# Standardise case and remove whitespace\n",
    "for df in [drugbank_dpi, chembl_dpi]:\n",
    "    df[\"Drug_Name\"] = df[\"Drug_Name\"].str.strip().str.lower()\n",
    "    df[\"Drug_Target\"] = df[\"Drug_Target\"].str.strip().str.upper()\n",
    "\n",
    "# Compare drug name sets\n",
    "chembl_drugs = set(chembl_dpi[\"Drug_Name\"].unique())\n",
    "drugbank_drugs = set(drugbank_dpi[\"Drug_Name\"].unique())\n",
    "shared_drugs = chembl_drugs & drugbank_drugs\n",
    "\n",
    "print(f\"Number of unique drug names in ChEMBL: {len(chembl_drugs)}\")\n",
    "print(f\"Number of unique drug names in DrugBank: {len(drugbank_drugs)}\")\n",
    "print(f\"Number of shared drug names: {len(shared_drugs)}\")\n",
    "\n",
    "# === Make one combined DPI dataframe containing the drug source ===\n",
    "# Track the drug source\n",
    "drugbank_dpi_with_source = drugbank_dpi.copy()\n",
    "chembl_dpi_with_source = chembl_dpi.copy()\n",
    "# Add source column to each DataFrame\n",
    "drugbank_dpi_with_source[\"Source\"] = \"DrugBank\"\n",
    "chembl_dpi_with_source[\"Source\"] = \"ChEMBL\"\n",
    "# Concatenate and drop duplicates: Group by drug and target, and merge source information\n",
    "combined_dpi_with_source = (\n",
    "    pd.concat([drugbank_dpi_with_source, chembl_dpi_with_source], ignore_index=True)\n",
    "    .groupby([\"Drug_Name\", \"Drug_Target\"])[\"Source\"]\n",
    "    .agg(lambda x: \"Both\" if set(x) == {\"ChEMBL\", \"DrugBank\"} else x.iloc[0])\n",
    "    .reset_index()\n",
    ")\n",
    "# Save to CSV\n",
    "combined_dpi_with_source.to_csv(\"../data/networks/combined_DPI_with_source.csv\", index=False)\n",
    "# =====\n",
    "\n",
    "# Concatenate and drop duplicates\n",
    "combined_dpi = pd.concat([drugbank_dpi, chembl_dpi], ignore_index=True)\n",
    "print(\"Total drug-target interactions before removing duplicates:\", len(combined_dpi))\n",
    "combined_dpi = combined_dpi.drop_duplicates()\n",
    "print(\"Total drug-target interactions after removing duplicates:\", len(combined_dpi))\n",
    "\n",
    "# Save to CSV\n",
    "combined_dpi.to_csv(\"../data/networks/combined_DPI.csv\", index=False)\n",
    "\n",
    "# Compute and print summary statistics\n",
    "num_unique_drugs = combined_dpi[\"Drug_Name\"].nunique()\n",
    "num_unique_targets = combined_dpi[\"Drug_Target\"].nunique()\n",
    "num_unique_interactions = combined_dpi.shape[0]\n",
    "\n",
    "print(f\"Total unique drug-target interactions: {num_unique_interactions}\")\n",
    "print(f\"Number of unique drugs: {num_unique_drugs}\")\n",
    "print(f\"Number of unique targets: {num_unique_targets}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71872a03",
   "metadata": {},
   "source": [
    "## Create the disease gene lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "025e28b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DEG\n",
      "0  ADAM10\n",
      "1    JAG1\n",
      "2    RHOA\n",
      "3     FN1\n",
      "4  FERMT2\n",
      "(70, 1)\n"
     ]
    }
   ],
   "source": [
    "# ====== STEP 1 ======\n",
    "\n",
    "# Load data\n",
    "step1 = pd.read_excel(\"../results/humanPVATsn/pathfindR/full/Sonia_network/step1_only_sonia.xls\")\n",
    "\n",
    "# Keep only gene columns\n",
    "step1_genes = step1[[\"Up_regulated_A\", \"Down_regulated_A\"]].copy()\n",
    "\n",
    "# Combine columns into one list\n",
    "step1_deg = (\n",
    "    step1_genes[\"Up_regulated_A\"].dropna().str.split(\", \").explode().tolist() +\n",
    "    step1_genes[\"Down_regulated_A\"].dropna().str.split(\", \").explode().tolist()\n",
    ")\n",
    "\n",
    "# Create the new DataFrame\n",
    "step1_deg = pd.DataFrame({\"DEG\": step1_deg})\n",
    "\n",
    "# Remove duplicates\n",
    "step1_deg = step1_deg.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(step1_deg.head())\n",
    "print(step1_deg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "92e075cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DEG\n",
      "0     APP\n",
      "1  ZBTB20\n",
      "2  CAMK2D\n",
      "3   PRKG1\n",
      "4   DCLK1\n",
      "(99, 1)\n"
     ]
    }
   ],
   "source": [
    "# ====== STEP 2 ======\n",
    "\n",
    "# Load data\n",
    "step2 = pd.read_excel(\"../results/humanPVATsn/pathfindR/full/Sonia_network/step2_only_sonia.xls\")\n",
    "\n",
    "# Keep only gene columns\n",
    "step2_genes = step2[[\"Up_regulated_A\", \"Down_regulated_A\", \"Up_regulated_B\", \"Down_regulated_B\",]].copy()\n",
    "\n",
    "# Combine columns into one list\n",
    "step2_deg = (\n",
    "    step2_genes[\"Up_regulated_A\"].dropna().str.split(\", \").explode().tolist() +\n",
    "    step2_genes[\"Down_regulated_A\"].dropna().str.split(\", \").explode().tolist() +\n",
    "    step2_genes[\"Up_regulated_B\"].dropna().str.split(\", \").explode().tolist() +\n",
    "    step2_genes[\"Down_regulated_B\"].dropna().str.split(\", \").explode().tolist()\n",
    ")\n",
    "\n",
    "# Create the new DataFrame\n",
    "step2_deg = pd.DataFrame({\"DEG\": step2_deg})\n",
    "\n",
    "# Remove duplicates\n",
    "step2_deg = step2_deg.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(step2_deg.head())\n",
    "print(step2_deg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "6fc5eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DEG\n",
      "0   CDH11\n",
      "1  COL1A1\n",
      "2  COL1A2\n",
      "3    FBN1\n",
      "4   FGFR1\n",
      "(56, 1)\n"
     ]
    }
   ],
   "source": [
    "# ====== STEP 3 ======\n",
    "\n",
    "# Load data\n",
    "step3 = pd.read_excel(\"../results/humanPVATsn/pathfindR/full/Sonia_network/step3_only_sonia.xls\")\n",
    "\n",
    "# Keep only gene columns\n",
    "step3_genes = step3[[\"Up_regulated_B\", \"Down_regulated_B\",]].copy()\n",
    "\n",
    "# Combine columns into one list\n",
    "step3_deg = (\n",
    "    step3_genes[\"Up_regulated_B\"].dropna().str.split(\", \").explode().tolist() +\n",
    "    step3_genes[\"Down_regulated_B\"].dropna().str.split(\", \").explode().tolist()\n",
    ")\n",
    "\n",
    "# Create the new DataFrame\n",
    "step3_deg = pd.DataFrame({\"DEG\": step3_deg})\n",
    "\n",
    "# Remove duplicates\n",
    "step3_deg = step3_deg.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(step3_deg.head())\n",
    "print(step3_deg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1b281f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       DEG\n",
      "0  PACSIN2\n",
      "1    ITGAV\n",
      "2    MYO9B\n",
      "3    ROBO1\n",
      "4    SLIT2\n",
      "(168, 1)\n"
     ]
    }
   ],
   "source": [
    "# ====== FULL DIFFERENTIATION ======\n",
    "\n",
    "# Load data\n",
    "full_diff = pd.read_excel(\"../results/humanPVATsn/pathfindR/full/Sonia_network/full_diff_only_sonia.xls\")\n",
    "\n",
    "# Keep only gene columns\n",
    "full_diff_genes = full_diff[[\"Up_regulated\", \"Down_regulated\",]].copy()\n",
    "\n",
    "# Combine columns into one list\n",
    "full_diff_deg = (\n",
    "    full_diff_genes[\"Up_regulated\"].dropna().str.split(\", \").explode().tolist() +\n",
    "    full_diff_genes[\"Down_regulated\"].dropna().str.split(\", \").explode().tolist()\n",
    ")\n",
    "\n",
    "# Create the new DataFrame\n",
    "full_diff_deg = pd.DataFrame({\"DEG\": full_diff_deg})\n",
    "\n",
    "# Remove duplicates\n",
    "full_diff_deg = full_diff_deg.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(full_diff_deg.head())\n",
    "print(full_diff_deg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "600847d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== SAVE FILES ======\n",
    "\n",
    "step1_deg.to_csv(\"../data/networks/step1_deg.csv\", index=False, header=False)\n",
    "step2_deg.to_csv(\"../data/networks/step2_deg.csv\", index=False, header=False)\n",
    "step3_deg.to_csv(\"../data/networks/step3_deg.csv\", index=False, header=False)\n",
    "full_diff_deg.to_csv(\"../data/networks/full_diff_deg.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bat_proximity_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
