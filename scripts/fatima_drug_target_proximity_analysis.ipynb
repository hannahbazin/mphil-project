{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda9a06-4bed-4243-beb3-937850b643b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def has_path(G,node_from,node_to): # returns true if the graph G has a path from source node(node_from) to target node (node_to)\n",
    "    return(nx.has_path(G,node_from,node_to))\n",
    "\n",
    "\n",
    "def get_shortest_path_length_between(G, source_id, target_id): #calculates shortest path length between source and target nodes in the graph G\n",
    "    return nx.shortest_path_length(G, source_id, target_id) \n",
    "\n",
    "'''\n",
    "The function below uses the previous two functions to calculate the path length \n",
    "between each source node (drug target) and its closest disease target.\n",
    "See Guney 2015 for more details on the approach (Network-based in silico drug efficacy screening).\n",
    "'''\n",
    "def calculate_closest_distance(network, nodes_from, nodes_to):\n",
    "    values_outer = []\n",
    "    for node_from in nodes_from: #nodes_from is a list of drug targets (eg. from drugbank, chembl, etc.)\n",
    "        values = [] # will store the shortest path length between a source node and all disease targets here\n",
    "        for node_to in nodes_to: #nodes_to is a list of known disease targets\n",
    "            # print(\"from - to\", node_from, node_to)\n",
    "            if not has_path(network,node_from,node_to): continue\n",
    "            val = get_shortest_path_length_between(network, node_from, node_to)\n",
    "            values.append(val)\n",
    "        if len(values) == 0:    continue\n",
    "        d = min(values) # the shortest path between a source node and its closest disease target\n",
    "        # print (d)\n",
    "        values_outer.append(d)\n",
    "    closest_d = numpy.mean(values_outer) # the average shortest path length between any source node (drug target) and its closest disease target\n",
    "    # print (d)\n",
    "    return closest_d\n",
    "\n",
    "\n",
    "def get_degree_binning(g, bin_size):\n",
    "    '''\n",
    "    This function creates the bins from a network g.\n",
    "    Starting from a list of nodes with the lowest degree, it adds nodes with the same degree to the bin until it reaches the set bin size.\n",
    "    If number of nodes with some degree is lower then bin size, it combines with other nodes with degree + 1 to meet bin size.\n",
    "    '''\n",
    "    degree_to_nodes = {}\n",
    "    # the below two lines compute the degree of each node in the graph.\n",
    "    # the setdefault method is used to add each node to a list of nodes with the same degree in the dictionary\n",
    "    for node, degree in g.degree(): \n",
    "        degree_to_nodes.setdefault(degree, []).append(node)\n",
    "    values = degree_to_nodes.keys()\n",
    "    values = sorted(values) # values becomes a list, sorted from lowest to highest degree\n",
    "    bins = []\n",
    "    i = 0 # this is the iterator that iterates over each degree, starting from the first item in the list (lowest degree)\n",
    "    while i < len(values):\n",
    "        low = values[i] # this is the i-th degree in the values list\n",
    "        val = degree_to_nodes[values[i]] # a list of the nodes with i-th degree (low)\n",
    "        while len(val) < bin_size:\n",
    "            # while the number of nodes in a bin is lower than the bin size, than nodes with degree i+1 will be added to the bin\n",
    "            # bin size is chosen by the user - in the paper this is set to 100\n",
    "            i += 1 # next iteration (move to the next degree in the list)\n",
    "            if i == len(values): # breaks when the last item in the list is reached\n",
    "                break\n",
    "            # starting from a list of nodes with the lowest degree, it adds nodes with degree lowest + 1 to the val list until it reaches the set bin size\n",
    "            val.extend(degree_to_nodes[values[i]]) # val will be extended with the next set of nodes with degree i+1 (low +1).\n",
    "        if i == len(values):\n",
    "            i -= 1\n",
    "        high = values[i] # this is the highest degree\n",
    "        i += 1\n",
    "        # print i, low, high, len(val)\n",
    "        if len(val) < bin_size:\n",
    "            low_, high_, val_ = bins[-1]\n",
    "            bins[-1] = (low_, high, val_ + val)\n",
    "        else:\n",
    "            bins.append((low, high, val))\n",
    "    return bins\n",
    "\n",
    "# this function lists all nodes in the same bin as each seed node\n",
    "def get_degree_equivalents(seeds, bins, g): \n",
    "    seed_to_nodes = {}\n",
    "    for seed in seeds:\n",
    "        d = g.degree(seed) #extract degree of the seed node\n",
    "        for l, h, nodes in bins: #it takes low, high degree and nodes for each bin\n",
    "            if l <= d and h >= d:\n",
    "                mod_nodes = list(nodes)\n",
    "                mod_nodes.remove(seed)\n",
    "                seed_to_nodes[seed] = mod_nodes\n",
    "                break\n",
    "    return seed_to_nodes\n",
    "\n",
    "    \n",
    "def pick_random_nodes_matching_selected(network, bins, nodes_selected, n_random, degree_aware=True, connected=False,\n",
    "                                        seed=None):\n",
    "    \"\"\"\n",
    "    Use get_degree_binning to get bins\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    values = []\n",
    "    nodes = network.nodes() # list of nodes in the network\n",
    "    for i in range(n_random): # decided by the user (how many times will the random iterations be repeated?) usually this is = 1000\n",
    "        if degree_aware:\n",
    "            if connected:\n",
    "                raise ValueError(\"Not implemented!\")\n",
    "            # the lines below pick random nodes matching the degree (same bin) of the real nodes\n",
    "            nodes_random = set()\n",
    "            node_to_equivalent_nodes = get_degree_equivalents(nodes_selected, bins, network) # lists nodes in the same bin as the node of interest\n",
    "            # now choose a random node from the same bin as the real node\n",
    "            for node, equivalent_nodes in node_to_equivalent_nodes.items():\n",
    "                chosen = random.choice(equivalent_nodes)\n",
    "                for k in range(20):  # Try to find a distinct node (at most 20 times) - to make sure it doesn't choose the same node\n",
    "                    if chosen in nodes_random:\n",
    "                        chosen = random.choice(equivalent_nodes)\n",
    "                nodes_random.add(chosen)\n",
    "            nodes_random = list(nodes_random)\n",
    "        else:\n",
    "            if connected:\n",
    "                nodes_random = [random.choice(nodes)]\n",
    "                k = 1\n",
    "                while True:\n",
    "                    if k == len(nodes_selected):\n",
    "                        break\n",
    "                    node_random = random.choice(nodes_random)\n",
    "                    node_selected = random.choice(network.neighbors(node_random))\n",
    "                    if node_selected in nodes_random:\n",
    "                        continue\n",
    "                    nodes_random.append(node_selected)\n",
    "                    k += 1\n",
    "            else:\n",
    "                nodes_random = random.sample(nodes, len(nodes_selected))\n",
    "        values.append(nodes_random)\n",
    "    return values\n",
    "\n",
    "def get_random_nodes(nodes, network, bins=None, n_random=1000, min_bin_size=100, degree_aware=True, seed=None):\n",
    "    '''\n",
    "    This function creates a n_random number of lists of random nodes with the same degree binning as the real nodes (when degree_aware=True).\n",
    "    usually n_random = 1000 because we often do 1000 iterations.\n",
    "    '''\n",
    "    if bins is None:\n",
    "        # Get degree bins of the network (if they aren't already supplied\n",
    "        bins = get_degree_binning(network, min_bin_size)\n",
    "    # pick the random nodes\n",
    "    nodes_random = pick_random_nodes_matching_selected(network, bins, nodes, n_random, degree_aware,\n",
    "                                                                         seed=seed)\n",
    "    return nodes_random\n",
    "\n",
    "def calculate_proximity(network, drug, nodes_from, nodes_to, nodes_from_random=None, nodes_to_random=None, bins=None,\n",
    "                        n_random=1000, min_bin_size=100, seed=452456):\n",
    "    \"\"\"\n",
    "    Calculate proximity from nodes_from to nodes_to\n",
    "    If degree binning or random nodes are not given, they are generated\n",
    "    \"\"\"\n",
    "\n",
    "    nodes_network = set(network.nodes())\n",
    "    nodes_from = set(nodes_from) & nodes_network # select only nodes_from (drug targets) that are located in the network\n",
    "    nodes_to = set(nodes_to) & nodes_network # select only nodes_to (disease targets) that are located in the network\n",
    "    if len(nodes_from) == 0 or len(nodes_to) == 0:\n",
    "        return None  # At least one of the node group not in network\n",
    "    d = calculate_closest_distance(network, nodes_from, nodes_to) # this is the real distance\n",
    "    \n",
    "    # now do 1000 iterations using random nodes\n",
    "    if bins is None and (nodes_from_random is None or nodes_to_random is None):\n",
    "        bins = get_degree_binning(network, min_bin_size)\n",
    "    if nodes_from_random is None:\n",
    "        nodes_from_random = get_random_nodes(nodes_from, network, bins=bins, n_random=n_random,\n",
    "                                             min_bin_size=min_bin_size, seed=seed)\n",
    "    if nodes_to_random is None:\n",
    "        nodes_to_random = get_random_nodes(nodes_to, network, bins=bins, n_random=n_random, min_bin_size=min_bin_size,\n",
    "                                           seed=seed)\n",
    "    random_values_list = zip(nodes_from_random, nodes_to_random)\n",
    "    values = numpy.empty(len(nodes_from_random))  # n_random\n",
    "    # now calculates the closest distance using random nodes. Repeat x1000\n",
    "    for i, values_random in enumerate(random_values_list):\n",
    "        #print('iteration ', i)\n",
    "        nodes_from, nodes_to = values_random\n",
    "        values[i] = calculate_closest_distance(network, nodes_from, nodes_to)\n",
    "    m, s = numpy.mean(values), numpy.std(values) # do mean and stdev of random iterations\n",
    "    if s == 0:\n",
    "        z = 0.0\n",
    "    else:\n",
    "        z = (d - m) / s\n",
    "    dict = {'drug': drug, 'distance': d, 'z_score': z}\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500a496f-5552-4da4-847d-5f5f80997e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import sys, time\n",
    "import numpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7be8e6-f41e-46fe-bee2-67a04cf81c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "drugbank = pd.read_csv(\"drug_target_list.csv\") # this is a dataframe with drug-target information\n",
    "# PPI network - this is the human interactome\n",
    "PPI_network = pd.read_csv(\"PPI_network_largest_component.csv\")\n",
    "PPI_network = PPI_network.iloc[:, [0, 1]]\n",
    "PPI_network.columns = ['source', 'target']\n",
    "g = nx.from_pandas_edgelist(PPI_network, 'source', 'target') # make graph object\n",
    "key_nodes = pd.read_csv('skyblue_tan/key_nodes_only_analysis/key_nodes.csv') # this is a list of known (or predicted) disease targets\n",
    "key_nodes = key_nodes['node'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "195ed65f-dd68-48d5-91ef-3980394b299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove disease targets that are not in the interactome and remove them\n",
    "key_nodes = [i for i in key_nodes if i in graph_nodes]\n",
    "\n",
    "# same filtering step for drug targets\n",
    "drug_targets = drugbank['geneID'].tolist()\n",
    "drug_targets = list(set(drug_targets))\n",
    "\n",
    "drug_targets = [i for i in drug_targets if i in graph_nodes]\n",
    "# now filter drugbank data frame\n",
    "out = drugbank['geneID'].isin(drug_targets)\n",
    "drugbank = drugbank[out]\n",
    "del out, drug_targets\n",
    "\n",
    "# list all drugs\n",
    "drug_list = drugbank['Drug_name'].tolist()\n",
    "drug_list = list(set(drug_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463043e7-00b6-4dfa-82a4-816b8dbf0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate bins\n",
    "min_bin_size = 100\n",
    "bins = get_degree_binning(g, min_bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23aff884-3965-4f5c-8570-21a9c5705cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_targets = key_nodes\n",
    "n_random = 1000\n",
    "seed = 452456\n",
    "min_bin_size = 100\n",
    "nodes_to_random = get_random_nodes(nodes=disease_targets, network=g, bins=bins, n_random=n_random, min_bin_size=min_bin_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b7487-ffa5-47e9-abc6-f116862483ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate proximity\n",
    "disease_targets = key_nodes\n",
    "n_random = 1000\n",
    "seed = 452456\n",
    "min_bin_size = 100\n",
    "nodes_to_random = get_random_nodes(nodes=disease_targets, network=g, bins=bins, n_random=n_random, min_bin_size=min_bin_size, seed=seed)\n",
    "\n",
    "# now test with given nodes_to random\n",
    "proximity_result = []\n",
    "n = 1\n",
    "for drug in drug_list:\n",
    "    begin = time.time() \n",
    "    nodes_from = drugbank[drugbank['Drug_name'] == drug].geneID.tolist()\n",
    "    drug_disease_proximity = calculate_proximity(g, drug, nodes_from, nodes_to=disease_targets, nodes_from_random=None, \n",
    "                                                 nodes_to_random=nodes_to_random, bins=bins, n_random=n_random, min_bin_size=100, \n",
    "                                                 seed=452456)\n",
    "    proximity_result.append(drug_disease_proximity)\n",
    "    print(n, ': ', drug ,' done!')\n",
    "    n += 1\n",
    "    end = time.time()\n",
    "    print(f\"runtime: {end - begin}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20fc1c-fa87-4e59-964e-d7138c297b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proximity_result_df = pd.DataFrame(proximity_result)\n",
    "proximity_result_df.to_csv('results_closest_d.csv', index = False)\n",
    "proximity_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212bcaa0-7fc2-4d38-b2f8-8877f53a1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find active drugs\n",
    "z_score_thres = -1.96\n",
    "active_drugs = proximity_result_df[proximity_result_df['z_score'] <= z_score_thres]\n",
    "active_drugs.to_csv('active_drugs.csv', index = False)\n",
    "active_drugs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
